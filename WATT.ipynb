{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WATT.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ARtmayawuRrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "d57b95ac-78a3-4236-9c96-448bcce15802"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 31kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58e4a000 @  0x7fa6a6f0d1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XjS7iuKJYPrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports, Documentation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Imports necessary Torch, Torchvision, NumPy, and plotting libraries. \n",
        "\n",
        "Main Docs: https://pytorch.org/docs/stable/_modules/torch.html\n",
        "\n",
        "Neural Networks: https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "Functional: https://pytorch.org/docs/stable/_modules/torch/nn/functional.html \n",
        "\n",
        "Dataset Creation: https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "NumPy: https://docs.scipy.org/doc/numpy-1.15.1/reference/\n",
        "\n",
        "Plotting: https://matplotlib.org/contents.html"
      ]
    },
    {
      "metadata": {
        "id": "jADWtyyBPPSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apvOSEE5ZBzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Operations\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Example: Set device to run on GPU if possible, otherwise run on CPU. GPU operations should be faster. \n",
        "\n",
        "Docs: https://pytorch.org/docs/stable/notes/cuda.html"
      ]
    },
    {
      "metadata": {
        "id": "Ft7qAC535g2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a7e9ae7-13ef-4682-e11b-79821ab75567"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "device"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "3p8HZVySCuac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Dataset Importing\n",
        "\n",
        "TO DO: Implement Pandas methods to read in data from our polling\n",
        "\n",
        "----\n",
        "\n",
        "Each feature needs to be converted from a *numpy* object to a *torch* object to be used with PyTorch's library. They are mostly interchangeable.\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "yLsKOD2WZg-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "01871b64-c89d-4ffe-9cc3-318280ccb292"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "n_features = 1\n",
        "n_samples = 100\n",
        "\n",
        "x, y = make_regression(n_samples = n_samples, n_features = n_features, noise = 10)\n",
        "\n",
        "fix, ax = plt.subplots()\n",
        "ax.plot(x, y, \".\")\n",
        "\n",
        "x = torch.from_numpy(x).float()\n",
        "y = torch.from_numpy(y).float()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0082ec1b70>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHNtJREFUeJzt3X+QXWWd5/F37E7/StKhu9PpNI06\nkXW+YOGgQNxhxQ04FIg4tVOItTAKZCC1JcXUkkWyuloaGYqZrUkN4KpDqWEHgkNG0XUUBaLAjDi4\ng4GSH67kq2ZTsEma5Ka7SafT3el00/vH/cHpm3O774/T995z7udVlUrf5557z/Pk3v6eJ9/z/Fgy\nOzuLiIgk11tqXQEREVlcCvQiIgmnQC8iknAK9CIiCadALyKScM21rkCYVOpo6FCgrq4ORkbGq12d\nuqC2N17bG7XdoLaX2/be3hVLwspj1aNvbm6qdRVqRm1vPI3ablDboxarQC8iIqVToBcRSTgFehGR\nhFOgFxFJOAV6EZGEU6AXEUk4BXoRkSqbnJpmz4EjTE5NV+V8dTlhSkQkqSanprn9/mcZHBqnv6eD\nz193Hm0tzbnn/JVhOpqX5MqioEAvIlJF+w8fY3AoPfN1cGic/YePcfqpK+e9AFSqoncxs7OA7wN3\nuftXzOw+4FxgKHPIVnf/kZl9HNgEvAF83d3vreS8IiJxNbBqGf09HbmAPrBqGVD4AhCFsgO9mS0D\nvgw8kffUf3P3H+Yd9wXgfcAUsMvMvufuw+WeW0Qkrtpamvn8deex//AxBlYty/XaC10AolBJj/44\n8GHg0wsc92+BXe5+BMDMngbeDzxcwblFROrC5NT0SUF7IW0tzSf11rMXgPHp2frJ0bv7NDBtZvlP\n/bmZ3QIcAv4cWAOkAs8fAvrne++uro6CC/v09q4ot8qxp7Y3nkZtN8Sj7RPHp/nC3T9l36ExTlu9\nnDs3rae9tf5ufUZdoweAIXd/3sw+A3wR+HneMaHLaAYVWqKzt3cFqdTRSusYS2p747W9UdsN8Wn7\nngNH2HdoDIB9h8Z4YfdrFefVK2l7oYtjpOPo3f0Jd38+8/AHwLuBA6R79VkDmTIRkVjL5tWByPPq\nUYq0R29m3wU2u/v/BS4EfgU8A2wzs1OAadL5+U1RnldEpBYK3VitN5WMujkX+Bvg94ATZnYl6VE4\n3zKzcWAM+DN3n8ikcXYCs8Bt2RuzIiJxF3Zjtd5UcjP2OdK99nzfDTn2O8B3yj2XiIiUT2vdiIgk\nnAK9iCRatRcQq0f1eedARCQCC60fU85kpzhKbstEpOHNt37MYi4iVm+UuhGRxJpvnHvYRSBocmqa\nl18Z5uVXhmOf9knm5UtEhPnHuc+3iNjk1DS33beLg8MTAPR1t7Nlw7rY9vjjWWsRkSIVGuc+30Vg\n/+FjuSAPcHB4ItJlg6tNqRsRaVjZi0B+T31g1TL6uttzj/u62+t2eYNiqEcvIpKnraWZLRvWsXdw\nFIC1/Z2xTduAAr2ISKi2lmbOfHt3rasRCaVuREQSToFeRCThFOhFRBJOgV5E6p7Wq6mMbsaKSF2L\nYqmCRlnTppDGa7GIxMp869UsZHJqmr2Do2zf6Rwcnkj8mjaFNFZrRSR25luqIEy2997T2cbWHb/M\nXSSg9AtFUlQU6M3sLOD7wF3u/hUzeyvwANAEDALXuPtxM/s46X1i3wC+7u73VlhvEWkQpezLGkzz\n9HS2MjR6fM7z9byB92Iq+2asmS0jvUfsE4HivwC+6u4fAH4HXJ857gvAxaS3HvwvZpaMWQgiUhWF\nlirIF0zzDI0ep2dlG5BewmDz1e9pyLQNVNajPw58GPh0oOxC4JOZnx8GbgUc2JXdENzMngben3le\nRCQy+WmezVe/l6HRyYa9CZtVyebg08C0mQWLl7l79v9Kh4B+YA2QChyTLS+oq6uD5uam0Od6e1eU\nW+XYU9sbT6O2G8pv+5c+dRGvvjbK29Z00t7azDsjrlc1RP25L+YlbkmJ5TkjI+Oh5b29K0iljlZS\np9hS2xuv7Y3Y7uwomVNWdtDV0Vx2L7y7YyljoxOMEb+hlZV87oUuEFG3eszM2t19AhgADmT+rAkc\nMwD8a8TnFZGYy9/so7erjQ0fOqOilSMbabvA+UQ9M/Zx4KOZnz8KPAY8A6wzs1PMbDnp/PzPIj6v\niMRc/mYfqZFJtu54ntvvf7bsGbELbRfYKCoZdXOumf0zsAG4OfPzbcB1ZvYzoBu4P9O7/wywk/SF\n4LbsjVkRkaz8zT6yKgnQwT1je1a20dPZVlEd42rJ7OxsretwklTqaGilGjFnmaW2N17bG7Hd2Rx9\ne0crX/vei5HMZn197Dh3bH+WodHjsUjfVJijD70HWr+tFZGGk93so7d3BWtWtkZyE3VodDI3capR\nZ8Zq9UoRqUvFTpJaSDB906gzY9WjF5FYW2j4ZClLKCRV47VYRBKj2OGT2f8dNCqlbkQktjR8sjgK\n9CISW8q/F0epGxGJLeXfi6MevYjEQqF9Y6ManZNk+pcRkUUR5WJiWrOmMvqXEpGKhAX04AJlfd3t\nbNmwrqLAXMm+saJALyJlCNuXNdjT3js4mlug7ODwBHsHRznz7SdvLFdsr7/UfWNlLgV6ESlJMI3S\n3dnKcBHLC0ydmGHPgSMn9fqLTcfopmtl9K8lIiUJplGGA5tv93W353raa/s76etu5+DwBL1dbfzD\nk787aYGyUtMxjT7pqRIK9CJSkmAaJeiqD75zTo97y4Z17D98jKkTM2zd8TyQDuh7B0dpWdpET2eb\n0jFVokAvIiXJplH2Do6yfadzcHiC7s5WHnziN6RGJnO99qz+njcvDH3d7bnXaPPu6tG/rIiULLuc\n8Kf/9BzueOA5ho5M5p7L9tq/+ePf5Hrr2YCe37sfGp1UOqYKNGFKRIqWP2lpaHRyTpAHcksSBPPv\n2YC+tr8z93xfdztTJ2bK3iZQihdpj97MLgQeAv5Ppugl4K+BB4AmYBC4xt2Ph76BiNSt4CiZvu52\nrr3UTkrLXHupsba/EyA0/56f9tm643lNgKqCxfiX/am7X5l9YGZ/B3zV3R8ys78ErgfuWYTzisgi\nCo6SOTg8kQvShfLshYZDtrU007K0KTfOXhOgFl81UjcXAj/I/PwwcHEVzikiEQuuFJkVTMvk98jn\nW4NGq05WV6Sbg2dSN38L/A7oBm4D/t7dV2eePx14wN3/3XzvMz09M9vc3BRZvUQkGhPHp/ntqyP8\n7XdfYH/qGKetXs6dm9bT3lp6cmDi+DSvvjbK29Z0lvV6CVWVzcF/Szq4fxt4B/BPeecIrUS+kZHx\n0PJKdkePO7W98dpeq3YvtCxB/yltfO6ac3PHjI1OMFbka/N1dyyd8/qsRv3MobK29/auCC2PNNC7\n+37gW5mHe8zsNWCdmbW7+wQwAByI8pwiEp1KtubTCpP1K9IcvZl93Mxuzfy8BugD/g74aOaQjwKP\nRXlOEYlOJVvzaVu/+hX1zdgfAOvN7GfA94Ebgc8B12XKuoH7Iz6niESkkpukusFavyK9GRuVVOpo\naKWUt1PbG0m95ugX67VBjfqZQ8U5+tD7oJoZKyJzLLQ1X6Et/Yp5rdSGPg2RGIpym75Sz6sbrvGj\nT0gkZhY72M53EdGWfvGkQC8SM5UE2+AWgEOjk7m/s0F9oYuItvSLJwV6kZgpN9gGg3hT0xJmZmZz\nf2eD+kIXEW3pF0/6lETqXH4qpdxgGwziMzOzc/7OBvViLiLa0i9+FOhF6lihVEo5wTYYxMN69NmL\nhnrsyaNPUaSORX3z8xOX/D6Q3t4vLEcP6rEnkQK9SB0rlEopdXhl2P8MssH8lOWti9oGqT0FepE6\nFpZKKWd4pYZFNjbNjBWpc/mzTctZPEzr0DQ29ehFYqac4ZW6ydrY9GmLxEy5QVs3WRuXUjciMZC/\nkJgWD5NS6FsiUueKvflaaCROrRZAk/qhT12kzi00YmZyapq9g6Ns3+kcHJ6YczHQapMCCvQidW++\nm6/BQJ4VvBhoWKVAFQO9md0F/CEwC9zs7ruqdW6RaosyXVJoLP3+w8eYOjEzJ8jD3OGTWm1SoEqB\n3szWA+909/PN7EzgfwLnV+PcItVWTrpkoQtDcMRM8P37utvp627n4PAEfd3tXHupsba/c85yBhpW\nKdX61P8I+EcAd3/ZzLrMrNPdR6t0fpGqKTVdMjk1zW337coF6y0b1s0bkIPvf3B4gs1Xv4eWpU1F\nXSSkMVUr0K8Bngs8TmXKQgN9V1cHzc1NoW/U27si8srFhdoeD8s72zlt9XL2HRrjtNXLOfuMNbS3\nFv5Ve/G3KQ4OTwDpwD0yPs0fDHQB4e3Of/917x6Y9/3jKk6fedSibnutvh2hO5VnjYyMh5ZrZ3i1\nPS4++4lzcumSsdEJxuY59vUj4yc9TqWOztvuUt4/juL4mUelkrYXukBUa8LUAdI9+KxTgcEqnVuk\n6vInNOVPeApa299JX3c7AN2drfT3FLekgSZMSbGqFeh/DFwJYGbnAAfcvTEv19JwsjdP79j+HLff\n/+xJwb6tpZlP/+k59HS2Mjx6nK07fhl6QRApV1W6A+7+czN7zsx+DrwB3FSN84rUg/luzgaHSQ6N\nHs8ds3dwlPHpWTqal6jXLhWr2jfI3T9TrXOJ1JP5Ng8pNEwybJarSLn07RFZZIUmPP3i5UOhwySn\nTsywdcfzgGazSjQU6EUWSTYtk78va7AnH9ycOzvRaXJqWrNZJVIK9CIRCgb3rTt+eVIwz/bssz35\nmZlZNlx2Bu87c/VJs1mVo5eo6BskEpFgT72nszV3c3VmZhZ4Mw2Tn7MPBvmstpZm3jrQuGPJJVoK\n9CIlKrQuTbCnPjR6nO7McMmsvu723Gu0/oxUk3aYEmH+CU35xxUaE5+/Afc1l/z+nNdee6nNSc9o\nwpNUi75l0vBKWW1yvjHx+T11YE6KZm1/Z3UaJJJHgV4aXimrTS60vnv+SpFK0Ug90DdPGl4pm3O0\ntTSz+er38uKeIf7g9J55927NH1YpUiv69knDK+Xm6OTUdG7YZH9PB5uvfm9RY+Q1u1VqSd88EYrf\nnCM/zXPH9mcZGj1ecIx89jjNbpVa0qgbkRIER9b0rGybsxBZcIw8QFNTetsFzW6VWlOPXqQEwTRP\ncPZrNpjnP68cvdQDfftEShRM84Tl9oPPn7K8tWb1FMlS6kYaQrEToko9XhOfJA707ZTEK3ZCVNiC\nZBoxI0mgb68kXjETouYsSLayjaEjk/MeLxInkQV6M9sA3A7syRT9xN3vMLOzgXuAWeBFd78xqnOK\nhMlfdKyYCVFzFiQ7Mklnx1JGx09oxIwkQtQ9+m+5+615ZXcDN7v7LjN70Mwuc/dHIz6vCFA4TbPQ\nhKjgxaCpaQmj4yfoWdnG5qvfq7SNxN6i3ow1sxZgrbvvyhQ9DFy8mOeUxpafptk7OAosfNM0ezHY\ncNkZuYlOQ0cmGRqdrE7FRRZR1F2V9Wb2GLAUuBU4CIwEnj8E9C/0Jl1dHTQ3N4U+19u7IoJqxpPa\nvrDlne0M9C5jf+oYAH//k99y9y0X0t5a3Fd91aoVPP7cPvYdGuO01cs5+4w1Rb92Megzb0xRt72s\nb7CZbQQ25hXvAL7o7j8ys/OB7cCleccsKeb9R0bGQ8t7ext3xx21vfi2X7n+HXzpOy8BcODwMV7Y\n/VpJN1M/+4lzcqNvXtj9Ws0mPOkzV9vLeW2Ysr697r4N2DbP8//bzHqBIaAn8NQAcKCcc4oUY3Jq\nmn948ne5x9ldnUqRvYGbzfX3dbdz7aWW27xbJG4iy9Gb2X81s6szP58FpNz9OLDbzC7IHHYF8FhU\n55TGFjapae/gKAeHJ3KPg7s6lSKY6z84PMHWHc+ftKOUSFxE2T15EHjAzD6Zed8bMuWbgK+Z2VuA\nZ9z98QjPKQ0qbHQNwH2P7c4d09fdntvVqdA+r4UER+FkaUy9xFVkgd7d9wEXhZT/GvhAVOcRgXTP\nPX90zdSJGVIjb46SueqD/+akNeKLnemaHYWzd3CU7Tudg8MTGlMvsaWEo8TO5NQ023f6nLL7HtvN\niek35pS1LE2P3Cplq8CgtpZmznx7N1s2rNN2gBJrWtRMYmf/4WNz8vAAqZFJXj86lXvc3dmaS9sE\n14gvp1euhcsk7vTNldjJn8U6MzNLX3c7kL5x2tPZyueuPW/OssHapFsamb7xEjuFNvcACgbzYrcK\nFEkiBXqJpexY9/zArmAucjIFeomlckbSiDQq3YyVWAobSZOv1F2lRJJKXSCJpYXWmFePX+RN+uZL\n3Shl9upCI2nKHTsvkkQK9FIXSu2BL3RRKGZXKZFGoUAvdaGUHngxFwWNnRd5k27GSl0oZfZqMTdi\nQTNaRbL0GyBVsVCqpZQeuNIyIqVRoJdFV2z+vdjZq0rLiJRGqRtZdPmpll+8fKjise1Ky4gUT4Fe\nFl0w/97UtIT7Ht2t3ZpEqqjs7pCZrQceAq539x9mys4G7gFmgRfd/cZM+WbgY5ny29z9kUorLvGR\nTbX84uVD3PdoegeosJE1pe4CJSLFKatHb2anA7cAT+c9dTdws7u/H1hpZpeZ2VrgKuAC4CPAnWbW\nVEGdJYbaWpp535mrC46syebx79j+nHr7IhErt9s0SHqj73uzBWbWAqx1912ZooeBi4F+4FF3nwJS\nZvYK8C7gpbJrLbE0301UzWQVWTxl9ejdfdzdZ/KKVwEjgceHSAf5NUAqpFwaQP7CYoVuola6C5SI\nFLZgj97MNgIb84q3uPvOBV66pMTynK6uDpqbw7M7vb0rFnp5YsWt7RPHp/nC3T9l36ExTlu9nDs3\nrae9tfBX7kufuohXXxvlbWs6Tzoubm2PSqO2G9T2KC0Y6N19G7CtiPdKAT2BxwPAgcwfCykvaGRk\nPLS8t3cFqdTRIqqSPHFs+54DR9h3aAyAfYfGeGH3awumY7o7ljI2OsFYoCyObY9Co7Yb1PZy217o\nAhHZ8Ep3PwHsNrMLMkVXAI8BTwKXm1mLmZ1KOtD/OqrzSv1SOkakPpR1M9bMLgc2A2cA55rZf3b3\nS4BNwNfM7C3AM+7+eOb4bwBPkR5eeaO7vxFJ7aWuaQarSH1YMjs7W+s6nCSVOhpaKf13rvZtr8VY\n93ppe7U1artBba8gdRN6D1RdLClacM2avu52rr3UWNvfqZ66SJ3TEghStOBY94PDE2zd8bwmN4nE\ngAK9FC14czVrvvXgRaQ+KNBL0bI3Vzdf/R76utsBjaYRiQMlV6UkbS3NnPn2brZsWKfRNCIxod9Q\nKUuxm4SISO0pdSMiknAK9CIiCadALwXlrzwpIvGkHL2EKnZDbxGpf+rRS6iwjUBEJJ4U6CWUVp4U\nSQ79X1xCaeVJkeRQj75BFXOjtdC2fyISL/oNjrlylg3WjVaRxqLf7hgrN2Dn32jdOzhKy9ImpWhE\nEkq/1TEWNjKmmGUJsjdas+vKb9/pHByeUO9eJKHK/o02s/XAQ8D17v7DTNk/A8uA7Fi8T7n7c2a2\nGfgY6a0Eb3P3RyqqtQBzA3YpI2OCN1qnTsywdcfzQGkXCxGJj3L3jD0duAV4OuTpP3P3XwWOXQtc\nBZwPrAR+ZmY73X2mnHPLmyoZGZO90To5NV3WxUJE4qPcHv0gcAVwbxHHXgQ86u5TQMrMXgHeBbxU\n5rkloNJVJDWMUiT5yvqtdvdxADMLe/ovzGwV8DKwCVgDpALPHwL6UaCvG1pyWCTZFgz0ZrYR2JhX\nvMXdd4Yc/iXgRXffY2b3ADeFHBO6S3lQV1cHzc1Noc/19q5Y6OWJpbY3nkZtN6jtUVow0Lv7NmBb\nMW/m7t8LPHwY+I/APwHBrv8AcGC+9xkZGQ8t7+1dQSp1tJiqJE4pbS9nbH09a9TPvVHbDWp7uW0v\ndIGILAqY2RLgJ8CV7v46cCHwK+BJ4BYz2wKsIh3ofx3VeWUuTYYSkXxlLYFgZpdnhlJ+CPgrM/ux\nu88CXweeMLOngLcCX3X3V4FvAE8B3wVudPc3Iql9wkSx/rtWnRSRfOXejP0R8KOQ8m8D3w4p/zLw\n5XLO1Sii6omXO7ZeRJJL/6evE+XOcs2n4ZIikk+rV9aJKNd/16qTIhKkSFAn1BMXkcWiaFJHNHFJ\nRBaDUjciIgmnQC8iknAK9CIiCadALyKScAr0IiIJp0AvIpJwCvQiIgmnQC8iknAK9CIiCadALyKS\ncAr0IiIJp0AvIpJwCvQiIglX1uqVZtYM3AucnnmPW939X8zsbOAeYBZ40d1vzBy/GfhYpvw2d38k\nisqLiMjCyu3RXwMcc/cLgBuAOzPldwM3u/v7gZVmdpmZrQWuAi4APgLcaWZNFdZbRESKVO569N8E\ndmR+TgE9ZtYCrHX3XZnyh4GLgX7gUXefAlJm9grwLuCl8qstIiLFKndz8BPAiczDTcCDwCpgJHDY\nIdJBfoj0xSC/vGCg7+rqoLk5vNPf27uinCongtreeBq13aC2R2nBQG9mG4GNecVb3H2nmd0EnAP8\nMdCbd8ySAm9ZqDxnZGQ8tLy3dwWp1NGFXp5Ianvjtb1R2w1qe7ltL3SBWDDQu/s2YFt+uZndQDrA\n/4m7nzCzFNATOGQAOJD5YyHlIiJSBWXdjDWzdwCfBK5w90nIpXN2m9kFmcOuAB4DngQuN7MWMzuV\ndKD/dcU1FxGRopR7M3Yj6d77I2a5zvolpPP1XzOztwDPuPvjAGb2DeAp0sMrb3T3NyqqtYiIFG3J\n7OxsretwklTqaGillLdT2xtJo7Yb1PYKcvSh90A1M1ZEJOEU6AMmp6bZc+AIk1PTta6KiEhkys3R\nJ87k1DS33/8sg0Pj9Pd08PnrzqOtRf88IhJ/6tFn7D98jMGh9Pj9waFx9h8+VuMaiYhEQ4E+Y2DV\nMvp7OgDo7+lgYNWyGtdIRCQaicpNTE5Ns//wMQZWLSs57dLW0sznrzuv7NeLiNSrxESzKHLsbS3N\nnH7qykWqoYhIbSQmdaMcu4hIuMQEeuXYRUTCJSZ1oxy7iEi4REVD5dhFRE6WmNSNiIiEU6AXEUk4\nBXoRkYRToBcRSTgFehGRhFOgFxFJuLrcYUpERKKjHr2ISMIp0IuIJJwCvYhIwinQi4gknAK9iEjC\nKdCLiCScAr2ISMLFapliM1sN3A+0AS3ALe7+TG1rVR1m1gzcC5xO+nO71d3/pba1qg4zWw88BFzv\n7j+sdX2qwczuAv4QmAVudvddNa5S1ZjZWcD3gbvc/Su1rk+1mNlfAx8g/fv9V+7+v6J677j16D8B\nPODuFwGfBW6vcX2q6RrgmLtfANwA3Fnj+lSFmZ0O3AI8Xeu6VEvmwvZOdz+f9Gf9P2pcpaoxs2XA\nl4Enal2XajKzi4CzMp/5h4C7o3z/WAV6d7/T3R/MPHwrsK+W9amyb5IOeAApoKeGdammQeAK4Eit\nK1JFfwT8I4C7vwx0mVlnbatUNceBDwMHal2RKnsK+Fjm59eBZWbWFNWbxyp1A2Bma4CHgRXAB2tc\nnapx9xPAiczDTcCD8xyeGO4+DmBmta5KNa0Bngs8TmXKRmtTnepx92lgusE+b9x9BjiWeXgD8Eim\nLBJ1G+jNbCOwMa94i7vvBNaZ2YeB+4BLql23xTZf283sJuAc4I+rX7PFtcBn3siW1LoCUh1m9h9I\nB/pI41rdBnp33wZsC5aZ2Xoz63L3EXd/xMy216h6iyqs7QBmdgPpAP8nmR5+ohRqdwM6QLoHn3Uq\n6RSWJJiZXQp8DviQu0eaqoxVjp50rvY6ADN7N/D/alud6jGzdwCfBK5w98la10cW1Y+BKwHM7Bzg\ngLsfrW2VZDGZ2UpgK/ARdx+O+v1jtUyxma0iPbxyBdBKetjZv9a2VtVhZn8JXAW8Gii+xN2nalSl\nqjCzy4HNwBmkc9WD7p64dF0+M/vvwL8H3gBucvcXalylqjCzc4G/AX6P9D2p/aQ7N5EHv3piZv8J\n+CLwm0Dxte7+avgrShOrQC8iIqWLW+pGRERKpEAvIpJwCvQiIgmnQC8iknAK9CIiCadALyKScAr0\nIiIJ9/8B97T8RB4HEi0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0082ec19e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PFO2YssyAy0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building Neural Nets\n",
        "\n",
        "TO DO: Add in Relu layers, predict function\n",
        "\n",
        "---\n",
        "\n",
        "Every neural net in PyTorch has three core components:\n",
        "\n",
        "**Model**: Defined by a class with minimally an \\__init__() and forward() methods.This is where you actually build the graph your data will be traversing. \n",
        "\n",
        "**Loss Function**: This is how you determine how accurate your data is. If you have a line/model/etc predicting where your data will fall, and you have a data point not on that line/model, the distance between that point and your line is called \"loss\". Minimizing this loss is the ultimate goal of ML. Simplest of these is the MSE -- mean squared error \n",
        "\n",
        "**Optimizer**: This is our gradient descent. [SGD = Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), or \"Iterative\". Let's us incrementally optimize a differentiable object. The learning rate controls how fast we're iterating. \"Too low\" rates will take too long, \"too high\" rates will overshoot and fail. \n",
        "\n",
        "\n",
        "We build this model using existing data, and then we want to know whether it's successful. This means we need both **Training Data** and **Test Data**. In both cases, we have data which we know its classification. A classic example would be \"Is this e-mail spam\", where we have an e-mail and its features (subject line, e-mail origin, percent caps in body) and have labeled whether or not it's spam. In our case, we have a set of features (CPU usage, page faults, etc) and will be labelling whether or not the system is considered \"thrashing\" at that time. We feed the system this data, and it builds a model. \n",
        "\n",
        "Then we expose it to our test data. This data should be similar to the training data, except we don't tell the model what it's classified as (spam/not spam, thrashing/not thrashing). This is how we determine whether the model was built correctly. \n",
        "\n",
        "We have to be careful not to [overfit](https://www.investopedia.com/terms/o/overfitting.asp) our data. Your model will always be amazing at predicting its own training data, but if you feed it the exact same data points when testing it, you're feeding your own confirmation bias. Remember, ML is essentially overcomplicated linear regression, you have points on a graph and are drawing a line to match it. If you test it using the exact same/near identical points it already had, you haven't learned anything about your model. "
      ]
    },
    {
      "metadata": {
        "id": "ELt0zBIzdmO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self, input_dimensions):\n",
        "    super().__init__()\n",
        "    self.linear_layer = nn.Linear(input_dimensions, 1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "model = MyModel(n_features).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.00005)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "x, y = x.to(device), y.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRINXKvhCit6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training Neural Nets\n",
        "\n",
        "TO DO: Training needs to be part of the model itself\n",
        "\n",
        "----\n",
        "\n",
        "WIP\n"
      ]
    },
    {
      "metadata": {
        "id": "qKuK7XgDwDNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "4ce78d86-a04a-499b-8741-8eba790efae0"
      },
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "y_next = model(x)\n",
        "loss = criterion(y_next.squeeze(1), y) #Squeeze prevents mismatch error \n",
        "\n",
        "loss.backward(loss) \n",
        "optimizer.step() #updates params of lin reg model \n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad(): \n",
        "  y_next = model(x)\n",
        "  \n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x.cpu().numpy(), y_next.cpu().numpy(), \".\", label = \"pred\")\n",
        "ax.plot(x.cpu().numpy(), y.cpu().numpy(), \".\", label = \"data\")\n",
        "ax.set_title(f\"MSE: {loss.item():0.1f}\")\n",
        "ax.legend();"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-89fde829b623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0my_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Squeeze prevents mismatch error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-a8ec4bca2352>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \"\"\"\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dim'"
          ]
        }
      ]
    }
  ]
}
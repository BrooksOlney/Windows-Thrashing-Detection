{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WATT.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ARtmayawuRrg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjS7iuKJYPrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports, Documentation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Imports necessary Torch, Torchvision, NumPy, and plotting libraries. \n",
        "\n",
        "Main Docs: https://pytorch.org/docs/stable/_modules/torch.html\n",
        "\n",
        "Neural Networks: https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "Functional: https://pytorch.org/docs/stable/_modules/torch/nn/functional.html \n",
        "\n",
        "Dataset Creation: https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "NumPy: https://docs.scipy.org/doc/numpy-1.15.1/reference/\n",
        "\n",
        "Plotting: https://matplotlib.org/contents.html"
      ]
    },
    {
      "metadata": {
        "id": "jADWtyyBPPSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apvOSEE5ZBzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Operations\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Example: Set device to run on GPU if possible, otherwise run on CPU. GPU operations should be faster. \n",
        "\n",
        "Docs: https://pytorch.org/docs/stable/notes/cuda.html"
      ]
    },
    {
      "metadata": {
        "id": "Ft7qAC535g2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3p8HZVySCuac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Dataset Importing\n",
        "\n",
        "----\n",
        "\n",
        "Each feature needs to be converted from a *numpy* object to a *torch* object to be used with PyTorch's library. They are mostly interchangeable.\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "3OjtQ9uPnLis",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLsKOD2WZg-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TrashingDataset(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    self.dataframe = pd.read_csv(csv_file)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "  \n",
        "  #WIP\n",
        "#   def __getitem__(self, index):\n",
        "#     item = self.dataframe.iloc[:,index]\n",
        "\n",
        "\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/stats.csv', 'r') as csv_file:\n",
        "  dataset = TrashingDataset(csv_file)\n",
        "  \n",
        "dataset.dataframe\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(dataset.dataframe)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFO2YssyAy0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building Neural Nets\n",
        "\n",
        "TO DO: Add in Relu layers, predict function\n",
        "\n",
        "---\n",
        "\n",
        "Every neural net in PyTorch has three core components:\n",
        "\n",
        "**Model**: Defined by a class with minimally an \\__init__() and forward() methods.This is where you actually build the graph your data will be traversing. \n",
        "\n",
        "**Loss Function**: This is how you determine how accurate your data is. If you have a line/model/etc predicting where your data will fall, and you have a data point not on that line/model, the distance between that point and your line is called \"loss\". Minimizing this loss is the ultimate goal of ML. Simplest of these is the MSE -- mean squared error \n",
        "\n",
        "**Optimizer**: This is our gradient descent. [SGD = Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), or \"Iterative\". Let's us incrementally optimize a differentiable object. The learning rate controls how fast we're iterating. \"Too low\" rates will take too long, \"too high\" rates will overshoot and fail. \n",
        "\n",
        "\n",
        "We build this model using existing data, and then we want to know whether it's successful. This means we need both **Training Data** and **Test Data**. In both cases, we have data which we know its classification. A classic example would be \"Is this e-mail spam\", where we have an e-mail and its features (subject line, e-mail origin, percent caps in body) and have labeled whether or not it's spam. In our case, we have a set of features (CPU usage, page faults, etc) and will be labelling whether or not the system is considered \"thrashing\" at that time. We feed the system this data, and it builds a model. \n",
        "\n",
        "Then we expose it to our test data. This data should be similar to the training data, except we don't tell the model what it's classified as (spam/not spam, thrashing/not thrashing). This is how we determine whether the model was built correctly. \n",
        "\n",
        "We have to be careful not to [overfit](https://www.investopedia.com/terms/o/overfitting.asp) our data. Your model will always be amazing at predicting its own training data, but if you feed it the exact same data points when testing it, you're feeding your own confirmation bias. Remember, ML is essentially overcomplicated linear regression, you have points on a graph and are drawing a line to match it. If you test it using the exact same/near identical points it already had, you haven't learned anything about your model. "
      ]
    },
    {
      "metadata": {
        "id": "ELt0zBIzdmO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self, data_in, hidden_layer, data_out):\n",
        "    super(MyModel, self).__init__()\n",
        "    \n",
        "    self.linear_layer_1 = nn.Linear(data_in, hidden_layer)\n",
        "    self.linear_layer_2 = nn.Linear(hidden_layer, data_out)\n",
        "    \n",
        "    self.learning_rate = 0.00005\n",
        "    self.training_iterations = 1000\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    h_relu = self.linear_layer_1(x).clamp(min=0)\n",
        "    y_pred = self.linear_layer_2(h_relu)\n",
        "    return y_pred\n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return nn.Sigmoid(x)\n",
        "  \n",
        "  #Returns a percentage from 0 to 1, how \"likely\" %\n",
        "  def predict(self, inputs):\n",
        "    return self.Sigmoid(dot(inputs, self.weights))\n",
        "\n",
        "model = MyModel(n_features).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.00005)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "x, y = x.to(device), y.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRINXKvhCit6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training Neural Nets\n",
        "\n",
        "TO DO: Training needs to be part of the model itself\n",
        "\n",
        "----\n",
        "\n",
        "WIP\n"
      ]
    },
    {
      "metadata": {
        "id": "qKuK7XgDwDNi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "y_next = model(x)\n",
        "loss = criterion(y_next.squeeze(1), y) #Squeeze prevents mismatch error \n",
        "\n",
        "loss.backward(loss) \n",
        "optimizer.step() #updates params of lin reg model \n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad(): \n",
        "  y_next = model(x)\n",
        "  \n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x.cpu().numpy(), y_next.cpu().numpy(), \".\", label = \"pred\")\n",
        "ax.plot(x.cpu().numpy(), y.cpu().numpy(), \".\", label = \"data\")\n",
        "ax.set_title(f\"MSE: {loss.item():0.1f}\")\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

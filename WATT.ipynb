{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of WATT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ARtmayawuRrg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjS7iuKJYPrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports, Documentation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Imports necessary Torch, Torchvision, NumPy, and plotting libraries. \n",
        "\n",
        "Main Docs: https://pytorch.org/docs/stable/_modules/torch.html\n",
        "\n",
        "Neural Networks: https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "Functional: https://pytorch.org/docs/stable/_modules/torch/nn/functional.html \n",
        "\n",
        "Dataset Creation: https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "NumPy: https://docs.scipy.org/doc/numpy-1.15.1/reference/\n",
        "\n",
        "Plotting: https://matplotlib.org/contents.html"
      ]
    },
    {
      "metadata": {
        "id": "jADWtyyBPPSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apvOSEE5ZBzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Operations\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Example: Set device to run on GPU if possible, otherwise run on CPU. GPU operations should be faster. \n",
        "\n",
        "**Sunview cannot use GPU operations**, don't use this unless we can run everything on Google's servers\n",
        "\n",
        "Docs: https://pytorch.org/docs/stable/notes/cuda.html"
      ]
    },
    {
      "metadata": {
        "id": "Ft7qAC535g2j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "#device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3p8HZVySCuac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Dataset Importing\n",
        "\n",
        "----\n",
        "\n",
        "Each feature needs to be converted from a *numpy* object to a *torch* object to be used with PyTorch's library. They are mostly interchangeable.\n",
        "\n",
        "Mount Colab drive, get CSV in same folder as program. When on Windows machine, this process will be simpler since it'll just be a relative path\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "3OjtQ9uPnLis",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPDftP6CZz8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TrashingDataset will accept a CSV file as input. It will split the data into two chunks: CPU/RAM usage, and hard faults. These will create two vectors for feature crossing, one (2xN) and one (1xN). \n",
        "\n",
        "Scaling can be done to reduce the range the data actually covers. I'm not sure yet if this actually helps or not."
      ]
    },
    {
      "metadata": {
        "id": "yLsKOD2WZg-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TrashingDataset(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    \n",
        "    #Read in data, split into RAM/CPU usages VS hard faults\n",
        "    self.dataframe = pd.read_csv(csv_file)\n",
        "    \n",
        "    self.faults = dataset.dataframe.iloc[:, 3:]\n",
        "    self.usage = dataset.dataframe.iloc[:, 0:2]\n",
        "\n",
        "    self.tensor_faults = torch.tensor(self.faults.values, dtype = torch.float)\n",
        "    self.tensor_usage = torch.tensor(self.usage.values, dtype = torch.float)\n",
        "    \n",
        "    self.batch_size_faults = self.tensor_faults.size()[0]\n",
        "    self.dimension_count_faults = self.tensor_faults.size()[1]\n",
        "\n",
        "    self.batch_size_usage = self.tensor_usage.size()[0]\n",
        "    self.dimension_count_usage = self.tensor_usage.size()[1]\n",
        "    \n",
        "#     self.scale()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "  \n",
        "  def scale(self):\n",
        "    \n",
        "    #Scales down data\n",
        "    usage_max, _ = torch.max(self.tensor_usage, 0)\n",
        "    faults_max, _ = torch.max(self.tensor_faults, 0)\n",
        "    self.tensor_usage = torch.div(self.tensor_usage, usage_max)  \n",
        "    self.tensor_faults = torch.div(self.tensor_faults, faults_max)\n",
        "    \n",
        "  #WIP\n",
        "#   def __getitem__(self, index):\n",
        "#     item = self.dataframe.iloc[:,index]\n",
        "\n",
        "\n",
        "with open('/content/gdrive/My Drive/Colab_Notebooks/stats.csv', 'r') as csv_file:\n",
        "  dataset = TrashingDataset(csv_file)\n",
        "  \n",
        "\n",
        "X = dataset.tensor_usage\n",
        "Y = dataset.tensor_faults\n",
        "  \n",
        "# print(dataset.tensor_faults)\n",
        "# print(dataset.tensor_usage)\n",
        "\n",
        "\n",
        "# dataset.dataframe\n",
        "\n",
        "# fig, ax = plt.subplots()\n",
        "# ax.plot(dataset.dataframe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFO2YssyAy0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building Neural Nets\n",
        "\n",
        "TO DO: Add in Relu layers, predict function\n",
        "\n",
        "---\n",
        "\n",
        "Every neural net in PyTorch has three core components:\n",
        "\n",
        "**Model**: Defined by a class with minimally an \\__init__() and forward() methods.This is where you actually build the graph your data will be traversing. \n",
        "\n",
        "**Loss Function**: This is how you determine how accurate your data is. If you have a line/model/etc predicting where your data will fall, and you have a data point not on that line/model, the distance between that point and your line is called \"loss\". Minimizing this loss is the ultimate goal of ML. Simplest of these is the MSE -- mean squared error \n",
        "\n",
        "**Optimizer**: This is our gradient descent. [SGD = Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), or \"Iterative\". Let's us incrementally optimize a differentiable object. The learning rate controls how fast we're iterating. \"Too low\" rates will take too long, \"too high\" rates will overshoot and fail. \n",
        "\n",
        "\n",
        "We build this model using existing data, and then we want to know whether it's successful. This means we need both **Training Data** and **Test Data**. In both cases, we have data which we know its classification. A classic example would be \"Is this e-mail spam\", where we have an e-mail and its features (subject line, e-mail origin, percent caps in body) and have labeled whether or not it's spam. In our case, we have a set of features (CPU usage, page faults, etc) and will be labelling whether or not the system is considered \"thrashing\" at that time. We feed the system this data, and it builds a model. \n",
        "\n",
        "Then we expose it to our test data. This data should be similar to the training data, except we don't tell the model what it's classified as (spam/not spam, thrashing/not thrashing). This is how we determine whether the model was built correctly. \n",
        "\n",
        "We have to be careful not to [overfit](https://www.investopedia.com/terms/o/overfitting.asp) our data. Your model will always be amazing at predicting its own training data, but if you feed it the exact same data points when testing it, you're feeding your own confirmation bias. Remember, ML is essentially overcomplicated linear regression, you have points on a graph and are drawing a line to match it. If you test it using the exact same/near identical points it already had, you haven't learned anything about your model. "
      ]
    },
    {
      "metadata": {
        "id": "P87JmW3BcLMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELt0zBIzdmO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    \n",
        "    self.input_dimensions = 2\n",
        "    self.output_dimensions = 1\n",
        "    self.hidden_layer = 3\n",
        "    \n",
        "    self.learning_rate = 0.000005\n",
        "    self.training_iterations = 1000\n",
        "    \n",
        "    self.weight1 = torch.randn(self.input_dimensions, self.hidden_layer) #[2,3]\n",
        "    self.weight2 = torch.randn(self.hidden_layer, self.output_dimensions) #[3,1]!\n",
        "    \n",
        "    self.linear_layer_1 = nn.Linear(self.input_dimensions, self.hidden_layer)\n",
        "    self.linear_layer_2 = nn.Linear(self.hidden_layer, 1)\n",
        "    \n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    h_relu = self.linear_layer_1(x)#.clamp(min=0)\n",
        "    y_pred = self.linear_layer_2(h_relu)\n",
        "    output = self.sigmoid(y_pred)\n",
        "    return output\n",
        "  \n",
        "#   def train(self, X, Y):\n",
        "#     output = self.forward(X)\n",
        "#     self.backward\n",
        "    \n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "  \n",
        "  #Returns a percentage from 0 to 1, how \"likely\" %\n",
        "  def predict(self, inputs):\n",
        "    weight = list(self.linear_layer_1.parameters())\n",
        "    self.weight = weight\n",
        "    self.weight_data = weight[0]\n",
        "    print(type(inputs))\n",
        "    print(type(self.weight))\n",
        "    print(type(self.weight_data))\n",
        "#     input1 = np.dot(inputs, weight)\n",
        "#     return self.sigmoid()\n",
        "\n",
        "  def save_weights(self, model):\n",
        "    torch.save(model, \"neural_net\")\n",
        "  \n",
        "  def load_weights(self):\n",
        "    torch.load(\"neural_net\")\n",
        "\n",
        "# model = MyModel()\n",
        "# model(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = MyModel()\n",
        "for i in range(model.training_iterations):\n",
        "    model.train()\n",
        "    Y_next = model(X)\n",
        "    optimizer = optim.SGD(model.parameters(), model.learning_rate) #Somehow works without this????\n",
        "    criterion = nn.MSELoss()\n",
        "    loss = criterion(Y_next, Y)\n",
        "    loss.backward(loss) \n",
        "    optimizer.step() #updates params of lin reg model \n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad(): \n",
        "      y_next = model(X)\n",
        "#     print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((Y - Y_next)**2).detach().item()))  # mean sum squared loss\n",
        "\n",
        "#     model.train(X, Y)\n",
        "\n",
        "test_tensor_usage = torch.FloatTensor([12, 15])\n",
        "test_tensor_faults = torch.FloatTensor([146])\n",
        "\n",
        "# usage_max, _ = torch.max(test_tensor_usage, 0)\n",
        "# faults_max, _ = torch.max(test_tensor_faults, 0)\n",
        "# test_tensor_usage = torch.div(test_tensor_usage, usage_max) \n",
        "# test_tensor_faults = torch.div(test_tensor_faults, faults_max) \n",
        "\n",
        "\n",
        "model.forward(test_tensor_usage)\n",
        "\n",
        "  \n",
        "# model.save_weights(model)\n",
        "# model.predict()\n",
        "\n",
        "# # x = dataset.tensor.to(device)\n",
        "# x = dataset.tensor.float()\n",
        "# type(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRINXKvhCit6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training Neural Nets\n",
        "\n",
        "TO DO: Training needs to be part of the model itself\n",
        "\n",
        "----\n",
        "\n",
        "WIP\n"
      ]
    },
    {
      "metadata": {
        "id": "qKuK7XgDwDNi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "y_next = model(X)\n",
        "y_next.size()\n",
        "x.size()\n",
        "# loss = criterion(y_next.squeeze(1), x) #Squeeze prevents mismatch error \n",
        "\n",
        "# loss.backward(loss) \n",
        "# optimizer.step() #updates params of lin reg model \n",
        "\n",
        "# model.eval()\n",
        "# with torch.no_grad(): \n",
        "#   y_next = model(x)\n",
        "  \n",
        "\n",
        "# fig, ax = plt.subplots()\n",
        "# ax.plot(x.cpu().numpy(), y_next.cpu().numpy(), \".\", label = \"pred\")\n",
        "# # ax.plot(x.cpu().numpy(), y.cpu().numpy(), \".\", label = \"data\")\n",
        "# ax.set_title(f\"MSE: {loss.item():0.1f}\")\n",
        "# ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsxuXxeo9WLe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test_list = torch.FloatTensor([92, 95, 2, 146])\n",
        "\n",
        "type(test_list)\n",
        "\n",
        "model.forward(test_list)\n",
        "\n",
        "# print(\"TEST\")\n",
        "# print(model.weight[0])\n",
        "# print(\"TEST\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
